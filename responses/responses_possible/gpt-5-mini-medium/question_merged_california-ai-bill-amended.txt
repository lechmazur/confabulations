merged_california-ai-bill-amended.txt
<question_number>1</question_number>
<answer>Concern that state lawmakers are prematurely regulating a still-unproven technology</answer>
<question_number>2</question_number>
<answer>Amended: liability only if technology causes real harm or imminent danger; Original: companies could be punished for failing to follow safety rules even if no harm occurred</answer>
<question_number>3</question_number>
<answer>Fear it would discourage open‑sourcing by tech giants, which would choke the progress of smaller AI companies</answer>
<question_number>4</question_number>
<answer>It requires pre‑release safety testing, which previously raised liability fears; the amendment ties liability to actual harm or imminent danger to address those concerns</answer>
<question_number>5</question_number>
<answer>Similar proactive state approach—another California effort to set new tech safety standards akin to prior 2020 privacy and 2022 child online safety laws</answer>
<question_number>6</question_number>
<answer>The bill uses state‑level regulation while critics argue regulation should be handled at the federal level</answer>
<question_number>7</question_number>
<answer>Amended version dropped creation of a new AI safety agency and shifted oversight to the existing California Government Operations Agency and limited liability to real harm</answer>
<question_number>8</question_number>
<answer>Both prioritize safety, but critics warn those safety rules could dampen innovation and open‑source development—a tension between safety and innovation</answer>
<question_number>9</question_number>
<answer>California's state‑level, proactive safety rules contrast with advocates' preference for federal regulation</answer>
<question_number>10</question_number>
<answer>Wiener says innovation and safety can coexist, while some tech companies say the bill will threaten innovation and open‑source development</answer>