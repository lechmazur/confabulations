merged_ai-california-bill-silicon-valley.txt
<question_number>1</question_number>
<answer>open-source sharing/development of models and code â€” because the threat of liability and legal action would discourage sharing and could push development to other states</answer>
<question_number>2</question_number>
<answer>OpenAI (its executives/the company)</answer>
<question_number>3</question_number>
<answer>the bill was created with input from the Center for A.I. Safety, a think tank with ties to effective altruism</answer>
<question_number>4</question_number>
<answer>Dario Amodei</answer>
<question_number>5</question_number>
<answer>the requirement to safety-test systems (e.g., those with development costs over $100 million) and associated liability/enforcement, which limits open-source and favors big firms</answer>
<question_number>6</question_number>
<answer>many tech leaders previously urged government guardrails for A.I., yet the industry now opposes California's proposed safeguards</answer>
<question_number>7</question_number>
<answer>Anthropic</answer>
<question_number>8</question_number>
<answer>restrictions that discourage open-source sharing and concentrate development (i.e., regulating creation rather than use)</answer>
<question_number>9</question_number>
<answer>the bill mandates safety testing of powerful systems despite studies (by OpenAI and others) finding today's A.I. not significantly more dangerous than search engines</answer>
<question_number>10</question_number>
<answer>the safety-testing rules that add liability and permit lawsuits by the state attorney general</answer>