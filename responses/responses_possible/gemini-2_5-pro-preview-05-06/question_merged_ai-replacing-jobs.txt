merged_ai-replacing-jobs.txt
<question_number>1</question_number>
<answer>A.I. might eliminate jobs workers find meaningless, only for the new human roles or newly created jobs to be equally or even more meaningless or psychologically degrading.</answer>
<other>The article states, "There is a possibility that lies somewhere between these scenarios, however, in which A.I. kills off some jobs that workers themselves deem meaningless, and even find psychologically degrading. If it did, would these workers be better off?" It then discusses how humans might end up "mindlessly skimming for errors" or how new jobs could be "even more meaningless."</other>
<question_number>2</question_number>
<answer>Facebook</answer>
<other>The article says, "He then spent more than a year at Facebook on a product whose primary customer at one point described it to the engineers as unhelpful."</other>
<question_number>3</question_number>
<answer>Stage 3: "OK, it can do everything I do, except it needs me when it breaks down, which is often."</answer>
<other>The article outlines Kevin Kelly's cycle: "Stage 3: 'OK, it can do everything I do, except it needs me when it breaks down, which is often.' Skip ahead to Stage 5: 'Whew, that was a job that no human was meant to do, but what about me?'"</other>
<question_number>4</question_number>
<answer>N/A</answer>
<other>The article mentions David Autor, an economist, discussing how new roles in empathic professions created due to A.I. would be "drained of that emotional difficulty -- but also drained of the attendant joy." However, it does not specifically state his view on "meaningful customer interactions in retail settings." The sociologist Allison Pugh is cited in relation to grocery clerks (retail) losing meaningful conversations, not the economist.</other>
<question_number>5</question_number>
<answer>Bartleby, the Scrivener</answer>
<other>The article states, "Herman Melville's 'Bartleby, the Scrivener' followed a law clerk -- the original quiet quitter..."</other>
<question_number>6</question_number>
<answer>Flunkies</answer>
<other>Kelly Eden's work was "administrative work like drafting emails for business people." The article links "executive assistant" work, a form of administrative work, to the "flunky" category of useless work identified by Graeber, stating, "An obvious candidate for 'flunky' automation is the executive assistant."</other>
<question_number>7</question_number>
<answer>John Maynard Keynes</answer>
<other>The article mentions, "Mr. Keynes's prediction in 1930 of 15-hour workweeks seems so far out of reach."</other>
<question_number>8</question_number>
<answer>A.I. babysitters</answer>
<other>According to David Autor, an M.I.T. labor economist, "Automated jobs are especially likely to require 'A.I. babysitters,' ... Companies will hire humans to edit the work that A.I. makes... and to police A.I.'s propensity to 'hallucinate.'"</other>
<question_number>9</question_number>
<answer>Bregman's movement focuses on "what needs to get done," not "what is your passion."</answer>
<other>The article states, "'We don't start with the question of 'What is your passion?'' Mr. Bregman said of his moral ambition movement. 'Gandalf didn't ask Frodo 'What's your passion?' He said, 'This is what needs to get done.''" This is contrasted with the mention of Sheryl Sandberg's "Lean In" circles as a model for the groups, implying a different core philosophy.</other>
<question_number>10</question_number>
<answer>Writing lines of code that didn't go live for an initiative that higher-ups decided to keep pursuing even though they knew it would never launch.</answer>
<other>The article states, "At Google, he worked for 15 months on an initiative that higher-ups decided to keep pursuing even though they knew it would never launch." And later, "That was what Mr. Wang felt when he wrote lines of code that didn't go live."</other>