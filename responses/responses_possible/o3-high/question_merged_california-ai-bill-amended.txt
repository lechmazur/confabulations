merged_california-ai-bill-amended.txt
<question_number>1</question_number>
<answer>concern that the state is “jumping the gun” by regulating a still‑unproven technology</answer>
<question_number>2</question_number>
<answer>liability now applies only after real or imminent harm, whereas originally it applied even with no harm</answer>
<question_number>3</question_number>
<answer>by discouraging open‑source code sharing, it could choke the progress of smaller A.I. companies</answer>
<question_number>4</question_number>
<answer>it mandates pre‑release safety testing yet ties liability to actual or imminent harm, easing fears of punishment before harm occurs</answer>
<question_number>5</question_number>
<answer>like the 2020 privacy and 2022 child online safety laws, it sets state‑level safety standards ahead of federal action</answer>
<question_number>6</question_number>
<answer>the bill imposes California‑state rules, while critics urge that regulation be handled federally</answer>
<question_number>7</question_number>
<answer>oversight is shifted to the existing Government Operations Agency instead of creating a new A.I. safety agency</answer>
<question_number>8</question_number>
<answer>the push for stringent safety rules parallels worries that those same rules will dampen innovation</answer>
<question_number>9</question_number>
<answer>it establishes state‑level safety requirements, contrasting with advocates who want federal‑level regulation</answer>
<question_number>10</question_number>
<answer>Wiener says innovation and safety can advance together, while tech companies warn the bill will hinder innovation</answer>
