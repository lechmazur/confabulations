merged_ai-data-restrictions.txt
<question_number>1</question_number>
<answer>They can't afford to license data directly from publishers</answer>

<question_number>2</question_number>
<answer>It primarily impacts later-arriving actors like smaller start-ups or researchers, not major tech companies who already have the data</answer>

<question_number>3</question_number>
<answer>Many researchers doubt that today's A.I. systems are capable of generating enough high-quality synthetic data to replace human-created data</answer>

<question_number>4</question_number>
<answer>The web will start shutting its doors</answer>

<question_number>5</question_number>
<answer>Major tech companies already have all the data, while smaller entities and researchers rely on public data sets that are increasingly being restricted</answer>

<question_number>6</question_number>
<answer>Major tech companies will retain access to data they've already collected while new entrants will face restrictions</answer>

<question_number>7</question_number>
<answer>Later-arriving actors (smaller start-ups or researchers) will be disproportionately affected by data restrictions compared to established companies</answer>

<question_number>8</question_number>
<answer>Website owners need new tools to give more precise control over their data, potentially allowing nonprofit/educational use while blocking commercial use</answer>

<question_number>9</question_number>
<answer>55%</answer>
<other>The article states that "as much as 45 percent of the data in one set, C4, had been restricted by websites' terms of service." This means 55% would remain unrestricted if all terms of service restrictions were enforced.</other>

<question_number>10</question_number>
<answer>75%</answer>
<other>The article states "25 percent of data from the highest-quality sources, has been restricted." This means 75% of high-quality data remains unrestricted.</other>