merged_ai-california-bill-silicon-valley.txt
<other>Gathering answers based on article:</other>
<question_number>1</question_number>
<answer>Open-source development, because liability concerns could push innovation elsewhere</answer>
<question_number>2</question_number>
<answer>N/A</answer>
<question_number>3</question_number>
<answer>The bill originated with input from the Center for A.I. Safety, linked to effective altruism</answer>
<question_number>4</question_number>
<answer>Dario Amodei</answer>
<question_number>5</question_number>
<answer>Mandatory safety tests that only large companies can afford</answer>
<question_number>6</question_number>
<answer>They previously urged regulation but now object to California’s attempt</answer>
<question_number>7</question_number>
<answer>Anthropic</answer>
<question_number>8</question_number>
<answer>The limits on open-source development might increase risks</answer>
<question_number>9</question_number>
<answer>Recent studies show current A.I. isn’t highly dangerous, yet the bill demands safety testing</answer>
<question_number>10</question_number>
<answer>The liability provisions might drive development to other regions</answer>